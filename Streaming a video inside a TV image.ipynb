{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from operator import itemgetter, attrgetter \n",
    "\n",
    "import win32api\n",
    "import win32con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting showing (screen) area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_greenScreen(img):\n",
    "    # set a range of green to detect the green screen\n",
    "    # [R value, G value, B value]\n",
    "    lower_green = np.array([0, 130, 0])     \n",
    "    upper_green = np.array([110, 255, 110])\n",
    "    \n",
    "    # fill the selected green area white\n",
    "    mask = cv2.inRange(img, lower_green, upper_green)\n",
    "    # reverse mask so the screen area will be filled black\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "    # smooth the mask area\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, np.ones((3,3),np.uint8))\n",
    "    \n",
    "    # apply mask on the given image\n",
    "    maskedScreen = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return mask, maskedScreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click(event, x, y, p1, p2):\n",
    "    #the function store the click points\n",
    "    \n",
    "    global gloablPts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        gloablPts.append((x, y))\n",
    "\n",
    "def draw_tv_screen(screen):\n",
    "    # copy the original image\n",
    "    img = screen.copy()                  \n",
    "    cv2.namedWindow(winname= \"TV image\")\n",
    "    # call The click function\n",
    "    cv2.setMouseCallback(\"TV image\", on_click)\n",
    "    txt = 'Click on the border of the screen area'\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow(\"TV image\", img)\n",
    "        cv2.putText(img, txt, (150, 100), cv2.FONT_HERSHEY_COMPLEX, .6, (0,0,0), 1)\n",
    "        # change cursor to a crooshair to make drawing easier\n",
    "        win32api.SetCursor(win32api.LoadCursor(0, win32con.IDC_CROSS))\n",
    "\n",
    "        # if we have 2 points draw line between them\n",
    "        if len(gloablPts) == 2:\n",
    "            cv2.line(img,(gloablPts[-2][0], gloablPts[-2][1]),(gloablPts[-1][0], gloablPts[-1][1]),(0,0,250), 2)\n",
    "\n",
    "        # if we have more than 2 points draw polygon\n",
    "        if len(gloablPts) > 2:    \n",
    "            cv2.fillPoly(img, np.int32([gloablPts]), (0, 0, 250), lineType=cv2.LINE_AA)\n",
    "\n",
    "        # if we have 4 points close the window and break\n",
    "        if len(gloablPts) == 4:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xFF\n",
    "        # wait for ESC key or q to exit\n",
    "        if k == 27 or k == ord('q'):         \n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate screen area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(mask):\n",
    "    # get image contours\n",
    "    ret,thresh = cv2.threshold(mask, 127, 255, 0)\n",
    "    contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    # sort contours in descending order\n",
    "    largest_cnt = sorted(contours, key=cv2.contourArea, reverse = True)\n",
    "    # screen is the second contour in the list, as the largest contour is the whole image\n",
    "    largest_cnt = largest_cnt[1]\n",
    "    \n",
    "    # find the rectangular that contains the screen\n",
    "    rect = cv2.minAreaRect(largest_cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    \n",
    "    # sort points according to their vertical coordinate then to their horizontal coordinate\n",
    "    sortedPts = sorted(box, key=itemgetter(1, 0))\n",
    "    # arrange point to be in a clockwise order\n",
    "    pts = [sortedPts[0], sortedPts[1], sortedPts[3], sortedPts[2]]\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Insert photo inside a photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global variable to store points of the selected screen\n",
    "gloablPts = []\n",
    "\n",
    "# import input image & TV screen image\n",
    "inputImage = cv2.imread('autumn.jpg')\n",
    "screen = cv2.imread('living3.jpg')\n",
    "\n",
    "# get image shapes\n",
    "(hScr, wScr) = screen.shape[:2]\n",
    "(hImg, wImg) = inputImage.shape[:2]\n",
    "\n",
    "# show screen image to select tv screen \n",
    "draw_tv_screen(screen)\n",
    "\n",
    "# fill screen with black\n",
    "pts = gloablPts\n",
    "maskedTV = cv2.fillPoly(screen, np.int32([pts]), (0, 0, 0), lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "# input points are as same as input image shape\n",
    "ptImg = np.float32([[0, 0], [wImg, 0], [wImg, hImg], [0, hImg]])\n",
    "# the output points are as same as tv screen\n",
    "ptTV = np.float32(pts)\n",
    "\n",
    "# Calculate transformation matrix\n",
    "matrix = cv2.getPerspectiveTransform(ptImg, ptTV)\n",
    "\n",
    "# warp input image to the screen\n",
    "warpedImg =cv2.warpPerspective(inputImage, matrix, (wScr,hScr))\n",
    "\n",
    "# mask the wraped image\n",
    "output = cv2.add(maskedTV, warpedImg)\n",
    "\n",
    "cv2.imshow('image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('image_inside.jpg', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Insert video inside a photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = cv2.imread('green.jpg')\n",
    "cv2.imshow('image', screen)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tv screen image\n",
    "screen = cv2.imread('green.jpg')\n",
    "\n",
    "# get image dimensions\n",
    "(hTV, wTV) = screen.shape[:2]\n",
    "\n",
    "# get the masked screen\n",
    "maskScr, maskedScreen = find_greenScreen(screen)\n",
    "\n",
    "# find the rectangular that contains the TV screen \n",
    "pts = get_contours(maskScr)\n",
    "\n",
    "# import input video\n",
    "video = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# prepare video parameters for saving\n",
    "# size is equal to image size not video\n",
    "size = int(screen.shape[1]),int(screen.shape[0])\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('tv_inside_img.mp4',fourcc, 20, size, True)\n",
    "\n",
    "# to display video\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        # get frame shape\n",
    "        (hFrame, wFrame) = frame.shape[:2]\n",
    "\n",
    "        # get frame border to insert it into the tv screen\n",
    "        ptFrame = np.float32([[0, 0], [wFrame, 0], [wFrame, hFrame], [0, hFrame]])\n",
    "        # convert TV screen into float\n",
    "        ptTV = np.float32(pts)\n",
    "        \n",
    "        # Calculate transformation matrix\n",
    "        matrix = cv2.getPerspectiveTransform(ptFrame, ptTV)\n",
    "        \n",
    "        # warp input video to the screen\n",
    "        warpedFrame =cv2.warpPerspective(frame, matrix, (wTV,hTV))\n",
    "        \n",
    "        # create a mask for the input video, which is the revese of the TV screen mask\n",
    "        maskVideo = cv2.bitwise_not(maskScr)\n",
    "        \n",
    "        # mask input video\n",
    "        maskedVideo = cv2.bitwise_and(warpedFrame, warpedFrame, mask= maskVideo)\n",
    "\n",
    "        finalFrame = cv2.add(maskedScreen, maskedVideo)\n",
    "        \n",
    "        # save video\n",
    "        out.write(finalFrame)\n",
    "\n",
    "        cv2.imshow('Video', finalFrame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            cv2.destroyWindow('Video')\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "out.release()         \n",
    "cv2.destroyWindow('Video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Insert video inside a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load screen video & input video\n",
    "scrVideo = cv2.VideoCapture('TVscreen.mp4')\n",
    "InputVideo = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# prepare video parameters for saving\n",
    "size = int(scrVideo.get(3)),int(scrVideo.get(4))\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('final_TV.mp4',fourcc, 20, size, True)\n",
    "\n",
    "# to display video\n",
    "while scrVideo.isOpened():\n",
    "    ret, scrFrame = scrVideo.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        # get frame shape\n",
    "        (hFrame, wFrame) = scrFrame.shape[:2]\n",
    "        \n",
    "        # get the masked screen\n",
    "        maskScr, maskedScreen = find_greenScreen(scrFrame)\n",
    "        \n",
    "        # find the rectangular that contains the TV screen \n",
    "        pts = get_contours(maskScr)\n",
    "        \n",
    "        # read the input video\n",
    "        ret, inputVideo = InputVideo.read()\n",
    "        \n",
    "        # get the shape of the frame\n",
    "        (hVideo, wVideo) = inputVideo.shape[:2]\n",
    "\n",
    "        # get frame border to transform it to the TV screen\n",
    "        ptVideo = np.float32([[0, 0], [wVideo, 0], [wVideo, hVideo], [0, hVideo]])\n",
    "        # convert TV screen into float\n",
    "        ptScreen = np.float32(pts)\n",
    "\n",
    "        # Calculate transformation matrix\n",
    "        matrix = cv2.getPerspectiveTransform(ptVideo, ptScreen)\n",
    "        \n",
    "        # warp input image to the screen\n",
    "        warpedVideo = cv2.warpPerspective(inputVideo, matrix, (wFrame,hFrame))\n",
    "        \n",
    "        # create a mask for the input video, which is the revese of the TV screen mask\n",
    "        maskVideo = cv2.bitwise_not(maskScr)\n",
    "        \n",
    "        # mask input video\n",
    "        maskedVideo = cv2.bitwise_and(warpedVideo, warpedVideo, mask= maskVideo)\n",
    "        \n",
    "        # add two videos together\n",
    "        output = cv2.add(maskedScreen, maskedVideo)\n",
    "        \n",
    "        # save video\n",
    "        out.write(output)\n",
    "        # show video\n",
    "        cv2.imshow('Video', output)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            cv2.destroyWindow('Video')\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "out.release()  \n",
    "cv2.destroyWindow('Video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
